{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tree\n",
    "\n",
    "I am organizing the repos this way and putting all the scripts under the new `data` repo.\n",
    "\n",
    "```console\n",
    "root/\n",
    "└── hillops/\n",
    "└── data/\n",
    "```\n",
    "\n",
    "Once all these are done, the final tree looks like below with `Index.md` containing a list of all the file with their genre and year-of-release listed.\n",
    "\n",
    "```console\n",
    "data/\n",
    "└── imsdb_scripts\n",
    "    ├── index.md\n",
    "    ├── json_screenplay\n",
    "    │   └── Aladdin.gpt_mini_parsed.json\n",
    "    └── raw_screenplay\n",
    "        ├── 10_Things_I_Hate_About_You.json\n",
    "        ├── 12.json\n",
    "        ├── 127_Hours.json\n",
    "        ├── 12_Monkeys.json\n",
    "        ├── 12_Years_a_Slave.json\n",
    "        ├── 12_and_Holding.json\n",
    "        ....- snhip....\n",
    "        ├── Yes_Man.json\n",
    "        ├── You've_Got_Mail.json\n",
    "        ├── You_Can_Count_On_Me.json\n",
    "        ├── Youth_in_Revolt.json\n",
    "        ├── Zero_Dark_Thirty.json\n",
    "        ├── Zerophilia.json\n",
    "        ├── Zootopia.json\n",
    "        ├── eXistenZ.json\n",
    "        └── xXx.json\n",
    "```\n",
    "\n",
    "# IMSDB Scripts\n",
    "\n",
    "IMSDB is a huge repository of scripts. This guy has some [scripts](https://huggingface.co/datasets/mattismegevand/IMSDb) to download the entire [imsdb]() script collection.\n",
    "\n",
    " - His instructions ask to clone the repor and run the scripts\n",
    " - HF says cloning is to use `git clone https://huggingface.co/<your-username>/<your-model-name>`\n",
    " - In any case, he has the entire scraped set _(244MB)_ on [his datasets folder](https://huggingface.co/datasets/mattismegevand/IMSDb/tree/main) as `data.jsonl`. Using that as a starting point to save time.\n",
    "\n",
    "# Split these out into one file per movie and store by title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ROOT = Path(\"~/bitbucket/\").expanduser()\n",
    "\n",
    "# Copy from https://huggingface.co/datasets/mattismegevand/IMSDb/tree/main as needed.\n",
    "SCRIPTS_DATASET = Path(\"~/data.jsonl\").expanduser()\n",
    "\n",
    "# Copy into REPO_ROOT/data/imsdb_scripts/raw_screenplay \n",
    "# once satisfied\n",
    "OUT_DIR = Path(\"~/scripts/\").expanduser()\n",
    "\n",
    "# Aiming for this type of structure.\n",
    "# OUT_DIR\n",
    "# ├── raw_scripts\n",
    "# │   ├── 10_Things_I_Hate_About_You.json\n",
    "# │   ├── 127_Hours.json\n",
    "# │   ├── ...snip...\n",
    "# │   ├── Year_One.json\n",
    "# │   ├── Yes_Man.json\n",
    "# │   ├── ...snip...\n",
    "# │   ├── Zerophilia.json\n",
    "# │   └── Zootopia.json\n",
    "# ├── Index.md\n",
    "\n",
    "if not OUT_DIR.exists():\n",
    "    print(f\"Creating {OUT_DIR}\")\n",
    "    os.makedirs(OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs panda's to load the jsonl ?\n",
    "# import pandas as pd\n",
    "# scripts_json_obj = pd.read_json(str(scripts_dataset), lines=True)\n",
    "import json\n",
    "with open(str(SCRIPTS_DATASET)) as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMSDb_opinion\n",
      "genres\n",
      "script_date\n",
      "IMSDb_rating\n",
      "poster\n",
      "submitted_by\n",
      "movie_release_date\n",
      "writers\n",
      "script\n",
      "average_user_rating\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "# What keys does this have ?\n",
    "# IMSDb_opinion\n",
    "# genres\n",
    "# script_date\n",
    "# IMSDb_rating\n",
    "# poster\n",
    "# submitted_by\n",
    "# movie_release_date\n",
    "# writers\n",
    "# script\n",
    "# average_user_rating\n",
    "# title\n",
    "for key in data[0].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "doWrite = False\n",
    "\n",
    "def canonicalize_title(origTitle: str) -> str:\n",
    "    return re.sub('^\".*\"$', '$1', \n",
    "                  re.sub('\\s+', '_', origTitle)\n",
    "                 )\n",
    "\n",
    "if doWrite :\n",
    "    for script_json in tqdm(data):\n",
    "        title_fname = canonicalize_title(script_json['title'])\n",
    "            \n",
    "        with open(str(OUT_DIR / \"raw_screenplay\" / title_fname) + \".json\", 'w') as out:\n",
    "            json.dump(script_json, out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a markdown index file to access all of these titles\n",
    "\n",
    "I want to group by year and genre. I have seen examples of grouping by a single key, but now want to group by year _(why not decade)_ and then by genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/vamsi/scripts/Index.md\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "# Thought I could sort by year but turns out many of them don't have years in them.\n",
    "# Could hit an LLM to ask which year the movie was released and complete my dataset.\n",
    "# For now, simply add all of these as metadata in the markdown file.\n",
    "def round_year_to_decade(year):\n",
    "    return int(round(year / 10.0) * 10)\n",
    "\n",
    "def json_to_md_link(d) -> str:\n",
    "    title = d['title']\n",
    "    file_name = canonicalize_title(title)\n",
    "    genres = re.sub('[\\[\\]]', '', d['genres'])           # serialized array.\n",
    "    metadata = f\"{genres} - {d['movie_release_date']}\"    \n",
    "    return f\" - [{title} - {metadata}](./raw_screenplay/{file_name}.json)\"\n",
    "\n",
    "doWrite = True\n",
    "if doWrite:\n",
    "    # Sort by the canonical title, case insensitive\n",
    "    # and generate a markdown list (include the metadata in the title)\n",
    "    # so a simple text search atleast will work for now.\n",
    "    data.sort(key=lambda x: canonicalize_title(x['title']).lower())\n",
    "    md_script_list = [json_to_md_link(d) for d in data]\n",
    "\n",
    "    # Generate the full markdown file and save it\n",
    "    md = '''\n",
    "# Scripts\n",
    "\n",
    "The script titles are listed alphabetically and linked to the full script. Genres and year of release are listed where available.\n",
    "''' + \"\\n\".join(md_script_list)\n",
    "\n",
    "    out_path = str(OUT_DIR / \"Index.md\")\n",
    "    with open(out_path,  'w') as out:\n",
    "        print(f\"Writing {out_path}\")\n",
    "        out.write(md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
