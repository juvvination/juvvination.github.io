{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference resolution using Fastcoref\n",
    "\n",
    "```console\n",
    "mamba install gradio\n",
    "pip install fastcoref\n",
    "```\n",
    "\n",
    "## Resources\n",
    " \n",
    " - https://pypi.org/project/fastcoref/\n",
    " - https://neurosys.com/blog/intro-to-coreference-resolution-in-nlp\n",
    " - https://huggingface.co/spaces/pythiccoder/FastCoref/blob/main/app.py\n",
    " - [Stanford CS224n Coreference notes](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/handouts/cs224n-lecture10-coreference.pdf)\n",
    "\n",
    "\n",
    "## Demo Code from HF Demo\n",
    "\n",
    "Actual demo is offline but the code looks simple enough to understand and it uses the Spacy span visualizer as well. So a good model for a CoRef test bench. It works just fine in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# from https://www.color-hex.com/color-palette/1041293\n",
    "pastel_colors = [\n",
    "# rainbow\n",
    "'#ffb3ba',\n",
    "'#ffdfba',\n",
    "'#ffffba',\n",
    "'#baffc9',\n",
    "'#bae1ff',\n",
    "# Spring valentine\n",
    "'#8478bf',\n",
    "'#bbabdb',\n",
    "'#ffe4e1',\n",
    "'#ffeb8e',\n",
    "'#ffc350'\n",
    "]\n",
    "\n",
    "def get_colors(num):\n",
    "    if num < len(pastel_colors):\n",
    "        return pastel_colors\n",
    "    \n",
    "    rand_colors = ['#%06X' % randint(0, 0xFFFFFF) for i in num - len(pastel_colors)]\n",
    "    return pastel_colors + rand_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsi/mambaforge/envs/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "02/23/2024 17:51:24 - INFO - \t HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
      "/home/vamsi/mambaforge/envs/ml/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "Some weights of the model checkpoint at biu-nlp/lingmess-coref were not used when initializing LingMessModel: ['longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LingMessModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LingMessModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "02/23/2024 17:51:36 - INFO - \t missing_keys: []\n",
      "02/23/2024 17:51:36 - INFO - \t unexpected_keys: []\n",
      "02/23/2024 17:51:36 - INFO - \t mismatched_keys: []\n",
      "02/23/2024 17:51:36 - INFO - \t error_msgs: []\n",
      "02/23/2024 17:51:36 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n",
      "02/23/2024 17:51:36 - INFO - \t HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "02/23/2024 17:51:36 - INFO - \t HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:51:36 - INFO - \t HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "02/23/2024 17:51:36 - INFO - \t HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "02/23/2024 17:51:37 - INFO - \t HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "02/23/2024 17:51:37 - INFO - \t HTTP Request: POST https://api.gradio.app/gradio-initiated-analytics/ \"HTTP/1.1 200 OK\"\n",
      "02/23/2024 17:51:37 - INFO - \t HTTP Request: POST https://api.gradio.app/gradio-launched-telemetry/ \"HTTP/1.1 200 OK\"\n",
      "02/23/2024 17:51:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe9e118e36648fdb44135e11672d45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:51:41 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73410011698409d8dc3e49164c017c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import span\n",
    "\n",
    "from random import randint\n",
    "\n",
    "# Replace with fastcoref for the fast model\n",
    "from fastcoref import LingMessCoref\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# uses a 2.36G weights file\n",
    "model = LingMessCoref()\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "default = \"Lionel Messi has won a record seven Ballon d'Or awards. He signed for Paris Saint-Germain in August 2021. “I would like to thank my family” said the Argentinian footballer. Messi holds the records for most goals in La Liga. Paris Saint-Germain hopes he will do the same in Ligue 1.\"\n",
    "\n",
    "def coref(text):\n",
    "    # Pre-process text copied from PDF\n",
    "    text = text.replace('\\t', ' ').replace('\\n', ' ')\n",
    "\n",
    "    preds = model.predict(texts=[text])\n",
    "\n",
    "    # as_strings=False returns spans\n",
    "    # as_strings=True returns actual mentions and resolutions\n",
    "    clusters = preds[0].get_clusters(as_strings=False)\n",
    "\n",
    "    # Spacy doc just for visualizing the spans via DisplaCy.\n",
    "    doc = nlp(text)\n",
    "    doc.spans[\"sc\"] = []\n",
    "\n",
    "    # Assign a color for each cluster. Make sure they are named the same.\n",
    "    color_hexs = get_colors(len(clusters))\n",
    "    color_keys = {\"cluster{}\".format(i): color_hexs[i] for i in range(len(clusters))}\n",
    "\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for sp in cluster:\n",
    "            doc.spans[\"sc\"] += [doc.char_span(sp[0], sp[1], \"cluster{}\".format(i))]\n",
    "    return displacy.render(doc, style=\"span\", options={\"colors\":color_keys}, page=True)\n",
    "\n",
    "iface = gr.Interface(fn=coref, \n",
    "                     inputs=gr.Textbox(label=\"Enter Text To Corefer with FastCoref\", lines=2, value=default), \n",
    "                     outputs=\"html\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore coref results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:52:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af525820086a401f8c3d9ebbc12bf186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:52:03 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151c18e066d349a5b18921e9f1ab3ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(texts=[default])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the preds is <class 'fastcoref.modeling.CorefResult'>\n",
      "Type of each cluster inside a pred is <class 'tuple'>\n",
      "((1, 2), (15, 15), (29, 29), (34, 34), (39, 42), (44, 44), (61, 61))\n",
      "((18, 22), (55, 59))\n"
     ]
    }
   ],
   "source": [
    "# Explore the types\n",
    "# This returns items of type: fastcoref.modeling.CorefResult\n",
    "print(f\"Type of the preds is {type(preds[0])}\")\n",
    "\n",
    "# A cluster is a list of all mentions of a particular named entity ?\n",
    "# Each mention (item in a cluster) is a tuple (a,b) which are indices to a span of text\n",
    "#   text[a:b] (index a till b inclusive)\n",
    "print(f\"Type of each cluster inside a pred is {type(preds[0].clusters[0])}\")\n",
    "for c in preds[0].clusters:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class, from ` ` has the following definition\n",
    "\n",
    "```python\n",
    "class CorefResult:\n",
    "    def __init__(self, text, clusters, char_map, reverse_char_map, coref_logit, text_idx):\n",
    "        self.text = text\n",
    "        self.clusters = clusters\n",
    "        self.char_map = char_map\n",
    "        self.reverse_char_map = reverse_char_map\n",
    "        self.coref_logit = coref_logit\n",
    "        self.text_idx = text_idx\n",
    "\n",
    "    def get_clusters(self, as_strings=True):\n",
    "        if not as_strings:\n",
    "            return [[self.char_map[mention][1] for mention in cluster] for cluster in self.clusters]\n",
    "\n",
    "        return [[self.text[self.char_map[mention][1][0]:self.char_map[mention][1][1]]\n",
    "                 for mention in cluster if None not in self.char_map[mention]] for cluster in self.clusters]\n",
    "\n",
    "    def get_logit(self, span_i, span_j):\n",
    "        if span_i not in self.reverse_char_map:\n",
    "            raise ValueError(f'span_i=\"{self.text[span_i[0]:span_i[1]]}\" is not an entity in this model!')\n",
    "        if span_j not in self.reverse_char_map:\n",
    "            raise ValueError(f'span_i=\"{self.text[span_j[0]:span_j[1]]}\" is not an entity in this model!')\n",
    "\n",
    "        span_i_idx = self.reverse_char_map[span_i][0]   # 0 is to get the span index\n",
    "        span_j_idx = self.reverse_char_map[span_j][0]\n",
    "\n",
    "        if span_i_idx < span_j_idx:\n",
    "            return self.coref_logit[span_j_idx, span_i_idx]\n",
    "\n",
    "        return self.coref_logit[span_i_idx, span_j_idx]\n",
    "\n",
    "    def __str__(self):\n",
    "        if len(self.text) > 50:\n",
    "            text_to_print = f'{self.text[:50]}...'\n",
    "        else:\n",
    "            text_to_print = self.text\n",
    "        return f'CorefResult(text=\"{text_to_print}\", clusters={self.get_clusters()})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Obama nominated Hillary Rodham Clinton as his  secretary of state on Monday. He chose her because she  had foreign affairs experience as a former First Lady.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Barack Obama nominated Hillary Rodham Clinton as his\t\n",
    "secretary\tof\tstate\ton\tMonday.\tHe\tchose\ther\tbecause\tshe\t\n",
    "had\tforeign\taffairs\texperience\tas\ta\tformer\tFirst\tLady.\"\"\".replace('\\t', ' ').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore samples from Stanford CS224n course\n",
    "\n",
    "While looking at some of the samples from [Stanfords CS224n from way back](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/handouts/cs224n-lecture10-coreference.pdf), I see that the references they display are more than the references that LingMess (and maybe the others) will display. Need to figure that out later.\n",
    "\n",
    "### Barack Hillary\n",
    "\n",
    "**\"Barack Obama nominated Hillary Rodham Clinton as his secretary of state on Monday. He chose her because she had foreign affairs experience as a former First Lady.\"**\n",
    "\n",
    "| Context | Output | Deltas |\n",
    "| :-- | :-- | :-- | \n",
    "| CS224n Expectation | ![](./img/coref-barack-hillary.png) | |\n",
    "| LingMess Output | ![](./img/coref-barack-hillary-lingmess.png) | missing _His secretary of state_, _first lady_|\n",
    "\n",
    "### CEO and his pay\n",
    "\n",
    "\"John Smith, CFO of Prime Corp. since 1986, saw his pay jump 20% to $1.3 million as the 57-year-old also became the financial services co.’s president\"S\n",
    "\n",
    "| Context | Output | Deltas |\n",
    "| :-- | :-- | :-- | \n",
    "| CS224n Expectation | ![](./img/coref-ceo-pay-expected.png) | |\n",
    "| LingMess Output | ![](./img/coref-ceo-pay-lingmess.png) | missing _his pay_, _1.3M$_, _The financial services co's president_|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:52:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bf2123ae5f4551a0c9e2fb7d0b3a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:52:42 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c126c027ff4e06a0806197e5bf19b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:52:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pred[0] ---\n",
      " The clusters as strings are - [['Barack Obama', 'his', 'He'], ['Hillary Rodham Clinton', 'her', 'she']]\n",
      " The clusters as spans are - [[(0, 12), (49, 52), (83, 85)], [(23, 45), (92, 95), (104, 107)]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94dcef35c864e4e84666f0807e4bd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 17:52:44 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff829a44da844f9d9e2a53f1d684e913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pred[0] ---\n",
      " The clusters as strings are - [['John Smith, CFO of Prime Corp. since 1986,', 'his', 'the 57-year-old'], ['Prime Corp.', 'the financial services co.’s']]\n",
      " The clusters as spans are - [[(0, 42), (47, 50), (83, 98)], [(19, 30), (111, 139)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 18:02:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a7a4ca7fd5473797a3606ee0083ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 18:02:23 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8832ada7584d4d0183a29f5191f5a4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 18:09:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff7c8b69824d4d87225839e073ac79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 18:09:26 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75abc1afd4142158ce8b100f52a83a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_preds(preds):\n",
    "    # Hmm, there is only one pred. When do yu have more than one pred ? When there are multiple possible\n",
    "    # interpretations ? In that case, is there a probabilistic weight to each ?\n",
    "    for i, pred in enumerate(preds):\n",
    "        print(f\" Pred[{i}] ---\")\n",
    "        print(f\" The clusters as strings are - {pred.get_clusters()}\")\n",
    "        print(f\" The clusters as spans are - {pred.get_clusters(as_strings=False)}\")\n",
    "\n",
    "samples = [\n",
    "\"Barack Obama nominated Hillary Rodham Clinton as his secretary of state on Monday. He chose her because she had foreign affairs experience as a former First Lady.\",\n",
    "\"John Smith, CFO of Prime Corp. since 1986, saw his pay jump 20% to $1.3 million as the 57-year-old also became the financial services co.’s president\"\n",
    "]\n",
    "\n",
    "for sample in samples:\n",
    "    preds = model.predict(texts = [sample])\n",
    "    print_preds(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
