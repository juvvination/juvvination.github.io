> Finish watching these later once actual prototype is up.


 - [Prompt injection in LLM Agents](https://www.youtube.com/watch?v=43qfHaKh0Xk&list=PLNg09XqZv0dHVDw7OiiRQJ315HnGHbDbG)
 - â¬œâ¬›â¬›â¬› TODO: [Deeplearning.ai - Navigating LLM threats: Detecting prompt injections and jailbreaks](https://www.youtube.com/watch?v=kH4ZoZSvddM)
 - â¬›â¬›â¬›â¬› ðŸ‘‰ [Navigating the threats: Detecting LLM prompt injections and Jailbreaks - Notebook](https://colab.research.google.com/drive/1RMjiJK9Nd-tP7kBXo8h9A0vtCCdY1ikS?usp=sharing)
 - â¬›â¬›â¬›â¬› [SimonWillison - The dual LLM pattern for building AI assistants that can resist prompt injection](https://simonwillison.net/2023/Apr/25/dual-llm-pattern/)

![](../img/LLM_PreventPromptInjection.svg)


